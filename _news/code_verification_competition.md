---
title: Code Verification Competition
frontpage: true
subtitle: Ensure Your Code’s Reproducibility & win prizes – Join the Code Verification Competition!
image: /assets/images/news/code-verification-competition.jpg
date: 2025-03-24
author: Minsi Li
tags: [competition, reproducibility, code]
---

Revisiting your data analysis after months of feedback from supervisors and journal reviewers can be overwhelming. Finding the right code version, locating the correct dataset, or re-running scripts often leads to frustration. If this sounds familiar, you’re not alone!  

Join our Code Verification Competition by following our guidelines to submit your code for reproduction. Enhance your code management skills—and have a chance to win a **€100 voucher**!

If you can confidently reproduce your code at any time, fantastic! Submit your code for replication to put your skills to the test and compete for €100 voucher.

## Competition details 
All submissions will be evaluated by a panel of experts. Assessment will be based on replication success, code, and documentation quality.

### Prizes
The top 10 winners will each receive a €100 voucher if there are at least 15 submissions, with winners announced at the Code Management Workshop in mid-May.

### Why Join?
Mastering reproducibility is a critical skill that not only strengthens the credibility of your work but also enhances collaboration and long-term impact. By joining the competition, you can

- Enhance the reproducibility of your research.
- Learn best practices for code and data management.
- Facilitate faster growth of your research field.
- Strengthen your preparation for funding applications.

### Who Can Participate?
PhD candidates, postdoctoral researchers, and professors at UT are invited to submit their data, code, and outputs. No restrictions on programming languages.

### Submission Guidelines
Your submission should aim to replicate a research output from your published paper, pre-print or an ongoing research project. This output could be an image or analysis result. To ensure reproducibility, please:

- If you want to reproduce publication or pre-prints, provide the link of the document with the results that will be reproduced  (e.g. a DOI).
- Place data, code, and outputs in the root directory. If the dataset is too large, share it via a repository.
- Include a README file with installation and usage instructions, along with an estimated running time. 
- Specify the environment and dependencies (e.g., .yml or similar).
- Submit your files as a ZIP archive or, preferably, host them on GitHub and share the repository with us. 

#### Tip
- To improve your chances, ask a friend or colleague to test your code before submitting.
- You can find a mini example of a submission in the repository. Additionally, use this checklist of reusable code to enhance your chances of success.
- Verify reproducibility using code-auditor. 

### How to Participate?
Interested? Send an email to <m.li-2@utwente.nl> by April 20, 2025, with:

- The DOI of your document or a brief description of your paper/project 
- A link to your code and data


{%
    include card.html
    title="Interested?"
    content="Send an email to Minsi Li by April 20, 2025, with:

- The DOI of your document or a brief description of your paper/project 
- A link to your code and data"
    cta="Get in touch!"
    cta_link="mailto:m.li-2@utwente.nl?subject=Code%20Verification%20Competition"
%}

### Evaluation Criteria
Submissions will be assessed by a committee based on:

- Replication success, considering computational complexity
- Code structure and documentation quality, ensuring clarity and usability

Join us to future-proof your code and promote transparent, reproducible science!
